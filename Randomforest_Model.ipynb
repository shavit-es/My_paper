{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jRB43j1BO-C",
        "outputId": "c2123710-75fc-4145-b049-3d95db9374d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(756, 200, 200, 3) (324, 200, 200, 3) (360, 200, 200, 3)\n",
            "(756, 120000) (324, 120000) (360, 120000)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Title: Image Classification using Random Forest\n",
        "@author: Team I\n",
        "\"\"\"\n",
        "\n",
        "# setting up the data path\n",
        "import os \n",
        "# os.chdir(\"C:/Users/prave/Downloads/Praveen/UConn/Predictive modeling/My Learnings/Python Project/\")\n",
        "\n",
        "# Importing all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# # Importing Train and Test datasets\n",
        "# train_data = pd.read_csv(\"datasets/fashion_mnist_train.csv\")\n",
        "# final_test_data = pd.read_csv(\"datasets/fashion_mnist_test.csv\")\n",
        "\n",
        "\n",
        "# # Splitting independent variables from the dependent variable in both training and testing\n",
        "# X_train = train_data.iloc[:,1:]\n",
        "# y_train = train_data.label.astype(\"str\")\n",
        "\n",
        "# X_final_test = final_test_data.iloc[:,1:]\n",
        "# y_final_test = final_test_data.label.astype(\"str\")\n",
        "\n",
        "\n",
        "\n",
        "# Splitting train data into training and validation datasets\n",
        "X_train, X_final_test, y_train, y_final_test = np.load(\"/content/drive/MyDrive/steel_surface_200.npy\", allow_pickle=True)\n",
        "x_train, x_test, y_train_v, y_test_v = train_test_split(X_train,y_train, test_size = 0.3, random_state = 43)\n",
        "print(x_train.shape, x_test.shape, X_final_test.shape)\n",
        "X_train=X_train.reshape(1080,120000)\n",
        "x_train=x_train.reshape(756,120000)\n",
        "x_test=x_test.reshape(324,120000)\n",
        "X_final_test=X_final_test.reshape(360,120000)\n",
        "print(x_train.shape, x_test.shape, X_final_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== Using Random Forest without hyper paramter tuning and clustering ===================\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(x_train,y_train_v)\n",
        "# Predictions on training and validation\n",
        "y_pred_train = rf.predict(x_train)\n",
        "    # predictions for test\n",
        "y_pred_test = rf.predict(x_test)\n",
        "    # training metrics\n",
        "print(\"Training metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_train_v, y_pred= y_pred_train))\n",
        "    \n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_test_v, y_pred= y_pred_test))\n",
        "\n",
        "\n",
        "# Predictions on testset\n",
        "y_pred_test = rf.predict(X_final_test)\n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AskTTg78DpFI",
        "outputId": "623fbe56-5b68-4c3e-c9f3-049a1c1c2321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       116\n",
            "           1       1.00      1.00      1.00       134\n",
            "           2       1.00      1.00      1.00       137\n",
            "           3       1.00      1.00      1.00       125\n",
            "           4       1.00      1.00      1.00       116\n",
            "           5       1.00      1.00      1.00       128\n",
            "\n",
            "    accuracy                           1.00       756\n",
            "   macro avg       1.00      1.00      1.00       756\n",
            "weighted avg       1.00      1.00      1.00       756\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.67      0.70        57\n",
            "           1       0.62      0.72      0.67        53\n",
            "           2       0.92      0.72      0.80        46\n",
            "           3       0.76      0.83      0.79        58\n",
            "           4       0.70      0.79      0.74        57\n",
            "           5       0.61      0.57      0.59        53\n",
            "\n",
            "    accuracy                           0.72       324\n",
            "   macro avg       0.73      0.71      0.72       324\n",
            "weighted avg       0.72      0.72      0.72       324\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.69      0.74        67\n",
            "           1       0.55      0.77      0.64        53\n",
            "           2       0.94      0.86      0.90        57\n",
            "           3       0.78      0.88      0.83        57\n",
            "           4       0.77      0.66      0.71        67\n",
            "           5       0.74      0.68      0.71        59\n",
            "\n",
            "    accuracy                           0.75       360\n",
            "   macro avg       0.76      0.76      0.75       360\n",
            "weighted avg       0.77      0.75      0.75       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "print(\"accuracy:\",accuracy_score(y_final_test, y_pred_test))\n",
        "print(\"Precision:\",precision_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"Recall:\",recall_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"F1-Score:\",f1_score(y_final_test, y_pred_test, average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75b490e-4d69-4ad4-b1c6-7cebb1299167",
        "id": "PCf3utHff7w1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.75\n",
            "Precision: 0.7660473743852008\n",
            "Recall: 0.75\n",
            "F1-Score: 0.7526071334437394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================== Using Grid Search for hyper parameter tuning ===================================\n",
        "clf = GridSearchCV(rf, param_grid={'n_estimators':[100,200],'min_samples_leaf':[2,3], 'max_depth':[4,8,10,16,24,48,128,256], 'min_samples_split':[2,3,5]}, scoring='accuracy')\n",
        "model = clf.fit(x_train,y_train_v)\n",
        "\n",
        "\n",
        "y_pred_train = model.predict(x_train)\n",
        "    # predictions for test\n",
        "y_pred_test = model.predict(x_test)\n",
        "    # training metrics\n",
        "print(\"Training metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_train_v, y_pred= y_pred_train))\n",
        "    \n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_test_v, y_pred= y_pred_test))\n",
        "\n",
        "\n",
        "# Predictions on testset\n",
        "y_pred_test = model.predict(X_final_test)\n",
        "    # test data metrics\n",
        "print(\"Test data metrics:\")\n",
        "print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMgGXeAaDpCv",
        "outputId": "0d85088f-dc11-4924-fc50-6438f293cf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       116\n",
            "           1       1.00      0.99      1.00       134\n",
            "           2       1.00      1.00      1.00       137\n",
            "           3       0.99      1.00      1.00       125\n",
            "           4       1.00      1.00      1.00       116\n",
            "           5       1.00      1.00      1.00       128\n",
            "\n",
            "    accuracy                           1.00       756\n",
            "   macro avg       1.00      1.00      1.00       756\n",
            "weighted avg       1.00      1.00      1.00       756\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.69        57\n",
            "           1       0.66      0.74      0.70        53\n",
            "           2       0.90      0.76      0.82        46\n",
            "           3       0.78      0.81      0.80        58\n",
            "           4       0.70      0.77      0.73        57\n",
            "           5       0.66      0.62      0.64        53\n",
            "\n",
            "    accuracy                           0.73       324\n",
            "   macro avg       0.74      0.73      0.73       324\n",
            "weighted avg       0.73      0.73      0.73       324\n",
            "\n",
            "Test data metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.73      0.76        67\n",
            "           1       0.58      0.75      0.66        53\n",
            "           2       0.92      0.86      0.89        57\n",
            "           3       0.82      0.86      0.84        57\n",
            "           4       0.84      0.72      0.77        67\n",
            "           5       0.69      0.69      0.69        59\n",
            "\n",
            "    accuracy                           0.77       360\n",
            "   macro avg       0.77      0.77      0.77       360\n",
            "weighted avg       0.78      0.77      0.77       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best score:', clf.best_score_)\n",
        "print('Best paramas:',clf.best_params_)\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "print(\"accuracy:\",accuracy_score(y_final_test, y_pred_test))\n",
        "print(\"Precision:\",precision_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"Recall:\",recall_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"F1_Score:\",f1_score(y_final_test, y_pred_test, average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjX4ge0ftFKI",
        "outputId": "fb5be28a-571a-4a7e-dee1-236fdc0a68c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.7076856047403276\n",
            "Best paramas: {'max_depth': 256, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}\n",
            "accuracy: 0.7666666666666667\n",
            "Precision: 0.7787372678430872\n",
            "Recall: 0.7666666666666667\n",
            "F1_Score: 0.7695824967616687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"accuracy:\",accuracy_score(y_final_test, y_pred_test))\n",
        "print(\"Precision:\",precision_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"Recall:\",recall_score(y_final_test, y_pred_test, average='weighted'))\n",
        "print(\"F1_Score:\",f1_score(y_final_test, y_pred_test, average='weighted'))\n"
      ],
      "metadata": {
        "id": "rtrK7f5L4g1S",
        "outputId": "17215cdb-23fd-40dd-df0c-c266ec3eeee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7666666666666667\n",
            "Precision: 0.7787372678430872\n",
            "Recall: 0.7666666666666667\n",
            "F1_Score: 0.7695824967616687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "scores_df = pd.DataFrame(clf.cv_results_)\n",
        "print(scores_df)\n",
        "scores_df.to_csv(\"/content/drive/MyDrive/RandomForest/Randomforest_scores.csv\", mode='w')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "digkpbNqlQXN",
        "outputId": "b1b04891-f66d-4234-9dff-715197fad83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "0        5.540103      0.042851         0.045287        0.005607   \n",
            "1       11.138705      0.425097         0.062490        0.001689   \n",
            "2        5.475683      0.114281         0.045506        0.004582   \n",
            "3       10.702446      0.108551         0.061367        0.008146   \n",
            "4        5.484154      0.074174         0.047928        0.001027   \n",
            "..            ...           ...              ...             ...   \n",
            "91      19.957472      0.478260         0.074617        0.016963   \n",
            "92      10.010913      0.229911         0.053754        0.001285   \n",
            "93      19.812665      0.225897         0.064047        0.007085   \n",
            "94      10.204691      0.525891         0.053261        0.001333   \n",
            "95      20.083933      0.121217         0.069321        0.005409   \n",
            "\n",
            "   param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
            "0                4                      2                       2   \n",
            "1                4                      2                       2   \n",
            "2                4                      2                       3   \n",
            "3                4                      2                       3   \n",
            "4                4                      2                       5   \n",
            "..             ...                    ...                     ...   \n",
            "91             256                      3                       2   \n",
            "92             256                      3                       3   \n",
            "93             256                      3                       3   \n",
            "94             256                      3                       5   \n",
            "95             256                      3                       5   \n",
            "\n",
            "   param_n_estimators                                             params  \\\n",
            "0                 100  {'max_depth': 4, 'min_samples_leaf': 2, 'min_s...   \n",
            "1                 200  {'max_depth': 4, 'min_samples_leaf': 2, 'min_s...   \n",
            "2                 100  {'max_depth': 4, 'min_samples_leaf': 2, 'min_s...   \n",
            "3                 200  {'max_depth': 4, 'min_samples_leaf': 2, 'min_s...   \n",
            "4                 100  {'max_depth': 4, 'min_samples_leaf': 2, 'min_s...   \n",
            "..                ...                                                ...   \n",
            "91                200  {'max_depth': 256, 'min_samples_leaf': 3, 'min...   \n",
            "92                100  {'max_depth': 256, 'min_samples_leaf': 3, 'min...   \n",
            "93                200  {'max_depth': 256, 'min_samples_leaf': 3, 'min...   \n",
            "94                100  {'max_depth': 256, 'min_samples_leaf': 3, 'min...   \n",
            "95                200  {'max_depth': 256, 'min_samples_leaf': 3, 'min...   \n",
            "\n",
            "    split0_test_score  split1_test_score  split2_test_score  \\\n",
            "0            0.592105           0.629139           0.668874   \n",
            "1            0.618421           0.642384           0.655629   \n",
            "2            0.625000           0.635762           0.662252   \n",
            "3            0.598684           0.649007           0.642384   \n",
            "4            0.618421           0.615894           0.668874   \n",
            "..                ...                ...                ...   \n",
            "91           0.684211           0.662252           0.768212   \n",
            "92           0.717105           0.662252           0.741722   \n",
            "93           0.657895           0.662252           0.735099   \n",
            "94           0.690789           0.642384           0.728477   \n",
            "95           0.717105           0.682119           0.754967   \n",
            "\n",
            "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
            "0            0.582781           0.682119         0.631004        0.039721   \n",
            "1            0.589404           0.695364         0.640241        0.035610   \n",
            "2            0.569536           0.675497         0.633609        0.036767   \n",
            "3            0.596026           0.668874         0.630995        0.028830   \n",
            "4            0.582781           0.675497         0.632293        0.034979   \n",
            "..                ...                ...              ...             ...   \n",
            "91           0.622517           0.741722         0.695783        0.052882   \n",
            "92           0.622517           0.728477         0.694414        0.044982   \n",
            "93           0.615894           0.721854         0.678599        0.044025   \n",
            "94           0.629139           0.695364         0.677231        0.036513   \n",
            "95           0.629139           0.715232         0.699712        0.042158   \n",
            "\n",
            "    rank_test_score  \n",
            "0                93  \n",
            "1                86  \n",
            "2                90  \n",
            "3                94  \n",
            "4                92  \n",
            "..              ...  \n",
            "91               19  \n",
            "92               27  \n",
            "93               66  \n",
            "94               72  \n",
            "95               11  \n",
            "\n",
            "[96 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ==================== Using Clustering and hyper parameter tuning ============================\n",
        "# # K- means clustering\n",
        "# kmeans = KMeans(n_clusters=10, init='k-means++')\n",
        "\n",
        "# # fitting K means to X_train\n",
        "# kmeans.fit(X_train)\n",
        "# X_train[\"k_means_label\"] = (kmeans.labels_)\n",
        "# X_train[\"k_means_label\"] = X_train[\"k_means_label\"].astype('str')\n",
        "\n",
        "# # Checking column type of K_means_label\n",
        "# X_train[\"k_means_label\"].dtypes\n",
        "# X_train.k_means_label[0:10]\n",
        "# y_train[0:10]\n",
        "\n",
        "# # fitting K means to X_final_test\n",
        "# kmeans.fit(X_final_test)\n",
        "# X_final_test[\"k_means_label\"] = (kmeans.labels_)\n",
        "# X_final_test[\"k_means_label\"] = X_final_test[\"k_means_label\"].astype('str')\n",
        "# y_final_test[0:10]\n",
        "\n",
        "# # Splitting train data into training and validation datasets\n",
        "# x_train, x_test, y_train_v, y_test_v = train_test_split(X_train,y_train, test_size = 0.3, random_state = 2)\n",
        "\n",
        "# # Hyper parameter tuning with new feature\n",
        "# clf = GridSearchCV(rf, param_grid={'n_estimators':[100,200],'min_samples_leaf':[2,3]})\n",
        "# model = clf.fit(x_train,y_train_v)\n",
        "\n",
        "# y_pred_train = model.predict(x_train)\n",
        "#     # predictions for test\n",
        "# y_pred_test = model.predict(x_test)\n",
        "#     # training metrics\n",
        "# print(\"Training metrics:\")\n",
        "# print(sklearn.metrics.classification_report(y_true= y_train_v, y_pred= y_pred_train))\n",
        "    \n",
        "#     # test data metrics\n",
        "# print(\"Test data metrics:\")\n",
        "# print(sklearn.metrics.classification_report(y_true= y_test_v, y_pred= y_pred_test))\n",
        "\n",
        "\n",
        "# # Predictions on testset\n",
        "# y_pred_test = model.predict(X_final_test)\n",
        "#     # test data metrics\n",
        "# print(\"Test data metrics:\")\n",
        "# print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))\n"
      ],
      "metadata": {
        "id": "379rouycDo49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # =================== Using 5 Fold Cross Validation to check the consistency of the final model ====================\n",
        "# sk_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# for train_index, test_index in sk_fold.split(x_train, y_train_v):\n",
        "#     train = [x_train.iloc[i,:] for i in train_index]\n",
        "#     y_trn_k = [y_train_v.iloc[i] for i in train_index]\n",
        "#     test = [x_train.iloc[i,:] for i in test_index]\n",
        "#     y_tst_k = [y_train_v.iloc[i] for i in test_index]\n",
        "#     # predictions for train\n",
        "#     model.fit(train, y_trn_k)\n",
        "#     y_pred_train = model.predict(train)\n",
        "#     # predictions for test\n",
        "#     y_pred_test = model.predict(test)\n",
        "#     # training metrics\n",
        "#     print(\"Training metrics:\")\n",
        "#     print(sklearn.metrics.classification_report(y_true= y_trn_k, y_pred= y_pred_train))\n",
        "    \n",
        "#     # test data metrics\n",
        "#     print(\"Test data metrics:\")\n",
        "#     print(sklearn.metrics.classification_report(y_true= y_tst_k, y_pred= y_pred_test))\n",
        "    \n",
        "\n",
        "# # predictions on train\n",
        "# y_pred_train = model.predict(X_train)\n",
        "#     # predictions for test\n",
        "# y_pred_test = model.predict(X_final_test)\n",
        "#     # training metrics\n",
        "# print(\"Training metrics:\")\n",
        "# print(sklearn.metrics.classification_report(y_true= y_train, y_pred= y_pred_train))\n",
        "    \n",
        "#     # test data metrics\n",
        "# print(\"Test data metrics:\")\n",
        "# print(sklearn.metrics.classification_report(y_true= y_final_test, y_pred= y_pred_test))"
      ],
      "metadata": {
        "id": "2-IbGNayGTPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}